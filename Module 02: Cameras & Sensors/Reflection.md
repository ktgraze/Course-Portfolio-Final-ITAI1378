### Module 02 Reflection
Though we did not have an assignment due for this module, the lecture itself and supplementary reading material was rich with foundational information regarding cameras and sensors.
Most real-world applications of computer vision involve one or both of these crucial technologies. From facial recognition, object detection, motion tracking, to image segmentation, all of which rely on a camera or sensor to generate useable image data for robust CV models. 
___
**Key Takeaways**:
* *Cameras*:
  - Common types:
    1. RGB - most common, capture color images and used in various applications including object detection, facial recognition, and self-driving cars.
    2. Depth Cameras - capture the distance between objects in an image, used in gesture recognition, augmented reality, and robotics applications.
    3. Thermal Cameras - capture the heat emitted by objects, used in surveillance, automotive, and firefighting.
  - Camera Specifications:
    1. Resolution - the number of pixels captured in an image.
    2. Frame Rate - how many images are captured per second.
    3. Field of View - determines the angles of the image captured.
  - Camera Callibration - The process of estimating and computing the intrinsic and extrinsic parameters of a camera, allowing for accurate 3D reconstruction of a scene.
* *Sensors*:
  - LiDAR Sensor - (Light Detection and Ranging), uses laser pulses to measure distances and create 3D maps of the environment. Common applications include self-driving cars and robotics.
  - Radar Sensor - (Radio Detection and Ranging), uses radio waves to detect and locate objects. Common applications include collision avoidance and adaptive cruise control in vehicle technology.
